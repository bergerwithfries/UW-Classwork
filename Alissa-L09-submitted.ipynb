{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment\n",
    "\n",
    "In this assignment, we develop on the ideas of linear regression we learned in the lecture to train multiple linear regression models and compare them. Recall that the HSB2 data contains students' scores in five different subjects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "matplotlib.rcParams['figure.figsize'] = [10, 7]\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as statsmodels\n",
    "import statsmodels.formula.api as sm\n",
    "#import the model from sklearn\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>read</th>\n",
       "      <th>write</th>\n",
       "      <th>math</th>\n",
       "      <th>science</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>57</td>\n",
       "      <td>52</td>\n",
       "      <td>41</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>68</td>\n",
       "      <td>59</td>\n",
       "      <td>53</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44</td>\n",
       "      <td>33</td>\n",
       "      <td>54</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>63</td>\n",
       "      <td>44</td>\n",
       "      <td>47</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>47</td>\n",
       "      <td>52</td>\n",
       "      <td>57</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   read  write  math  science\n",
       "0    57     52    41       47\n",
       "1    68     59    53       63\n",
       "2    44     33    54       58\n",
       "3    63     44    47       53\n",
       "4    47     52    57       53"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hsb2 = pd.read_csv('./data/hsb2.csv')\n",
    "X = hsb2[['read', 'write', 'math', 'science']]\n",
    "Y = hsb2['socst']\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    57\n",
       "1    61\n",
       "2    31\n",
       "3    56\n",
       "4    61\n",
       "Name: socst, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#type(Y)\n",
    "Y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>female</th>\n",
       "      <th>race</th>\n",
       "      <th>ses</th>\n",
       "      <th>schtyp</th>\n",
       "      <th>prog</th>\n",
       "      <th>read</th>\n",
       "      <th>write</th>\n",
       "      <th>math</th>\n",
       "      <th>science</th>\n",
       "      <th>socst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>52</td>\n",
       "      <td>41</td>\n",
       "      <td>47</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>121</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>68</td>\n",
       "      <td>59</td>\n",
       "      <td>53</td>\n",
       "      <td>63</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>86</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>33</td>\n",
       "      <td>54</td>\n",
       "      <td>58</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>141</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>63</td>\n",
       "      <td>44</td>\n",
       "      <td>47</td>\n",
       "      <td>53</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>47</td>\n",
       "      <td>52</td>\n",
       "      <td>57</td>\n",
       "      <td>53</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  female  race  ses  schtyp  prog  read  write  math  science  socst\n",
       "0   70       0     4    1       1     1    57     52    41       47     57\n",
       "1  121       1     4    2       1     3    68     59    53       63     61\n",
       "2   86       0     4    3       1     1    44     33    54       58     31\n",
       "3  141       0     4    3       1     3    63     44    47       53     56\n",
       "4  172       0     4    2       1     2    47     52    57       53     61"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hsb2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 / 9\n",
    "- Use the reading, writing, math and science scores to predict a student's score in social studies. Train your model using `LinearRegression` in `sklearn`. Add the model's predictions to the data as a new column called `socst_pred_skl`. <span style=\"color:red\" float:right>[5 point] [of 28 pts] </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model is at y= [ 0.38075199  0.37518056  0.13222368 -0.02794164] x_f +  7.206027496188192\n",
      "The accuracy is  47.72\n"
     ]
    }
   ],
   "source": [
    "#initialize the model \n",
    "model = LinearRegression()\n",
    "#fit the data \n",
    "    #input is reading, writing, math, and science scores (X)\n",
    "    #output is scores in social studies (Y)\n",
    "model.fit(X, Y)\n",
    "#Predictions are added as a new column\n",
    "hsb2[\"socst_pred_skl\"] = model.predict(X)\n",
    "#Print the linear model\n",
    "print(\"The model is at y=\",model.coef_,\"x_f + \", model.intercept_)\n",
    "#Print the score (aka mean accuracy) of the model\n",
    "print(\"The accuracy is \", round(model.score(X,Y)*100,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 / 9\n",
    "- Train the same model a second time, but this time use `sm.ols` in `statsmodels` to do it. Add the model's predictions to the data as a new column called `socst_pred_ols`. <span style=\"color:red\" float:right>[3 point] of 28 pts </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model is at y= read       0.380752\n",
      "write      0.375181\n",
      "math       0.132224\n",
      "science   -0.027942\n",
      "dtype: float64 x_f +  7.20602749618822\n",
      "The accuracy is  47.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alissa\\AppData\\Local\\Temp\\ipykernel_7988\\2004242341.py:17: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  print(\"The model is at y=\",results.params[1:],\"x_f + \", results.params[0])\n"
     ]
    }
   ],
   "source": [
    "# Add a constant term to X (required for statsmodels OLS)\n",
    "    #renamed X because it added a constant, which threw off the concatenation below\n",
    "X_OLS = statsmodels.add_constant(X)\n",
    "\n",
    "#initialize the model \n",
    "model_statsmodels = statsmodels.regression.linear_model.OLS(Y,X_OLS)\n",
    "\n",
    "#fit the data \n",
    "    #input is reading, writing, math, and science scores (X)\n",
    "    #output is scores in social studies (Y)\n",
    "results = model_statsmodels.fit()\n",
    "\n",
    "#Predictions are added as a new column\n",
    "hsb2[\"socst_pred_ols\"] = results.predict(X_OLS)\n",
    "\n",
    "#Print the linear model\n",
    "print(\"The model is at y=\",results.params[1:],\"x_f + \", results.params[0])\n",
    "\n",
    "#Print the score (aka mean accuracy) of the model\n",
    "print(\"The accuracy is \", round(results.rsquared*100,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 / 9\n",
    "- Check that the predictions from the two models are the same. <span style=\"color:red\" float:right>[1 point] of 28 pts</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>socst_pred_skl</th>\n",
       "      <th>socst_pred_ols</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>52.405000</td>\n",
       "      <td>52.405000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>7.415957</td>\n",
       "      <td>7.415957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>36.947826</td>\n",
       "      <td>36.947826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>46.898075</td>\n",
       "      <td>46.898075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>52.549074</td>\n",
       "      <td>52.549074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>58.140526</td>\n",
       "      <td>58.140526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>67.765579</td>\n",
       "      <td>67.765579</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       socst_pred_skl  socst_pred_ols\n",
       "count      200.000000      200.000000\n",
       "mean        52.405000       52.405000\n",
       "std          7.415957        7.415957\n",
       "min         36.947826       36.947826\n",
       "25%         46.898075       46.898075\n",
       "50%         52.549074       52.549074\n",
       "75%         58.140526       58.140526\n",
       "max         67.765579       67.765579"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Print description statistics to compare the predictions\n",
    "hsb2[[\"socst_pred_skl\",\"socst_pred_ols\"]].describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4 / 9\n",
    "- Print the model summary from the model we trained with `sm.ols`. The formula uses a format similar to `Y ~ X_1 + X_2`. Interpret the model's coefficients and write a few brief sentences about what the model is telling us. <span style=\"color:red\" float:right>[5 point] of 28 pts</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  socst   R-squared:                       0.477\n",
      "Model:                            OLS   Adj. R-squared:                  0.466\n",
      "Method:                 Least Squares   F-statistic:                     44.49\n",
      "Date:                Tue, 18 Mar 2025   Prob (F-statistic):           1.65e-26\n",
      "Time:                        14:41:41   Log-Likelihood:                -693.15\n",
      "No. Observations:                 200   AIC:                             1396.\n",
      "Df Residuals:                     195   BIC:                             1413.\n",
      "Df Model:                           4                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          7.2060      3.611      1.995      0.047       0.084      14.328\n",
      "read           0.3808      0.080      4.759      0.000       0.223       0.539\n",
      "write          0.3752      0.080      4.669      0.000       0.217       0.534\n",
      "math           0.1322      0.089      1.487      0.139      -0.043       0.308\n",
      "science       -0.0279      0.079     -0.352      0.725      -0.185       0.129\n",
      "==============================================================================\n",
      "Omnibus:                        6.177   Durbin-Watson:                   1.932\n",
      "Prob(Omnibus):                  0.046   Jarque-Bera (JB):                6.368\n",
      "Skew:                          -0.428   Prob(JB):                       0.0414\n",
      "Kurtosis:                       2.827   Cond. No.                         691.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "#Print the model summary from the model\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the Prob of the F-statistic is so low (< 0.05), it suggests this model is highly significant. And because two coefficients of read and write have p-value < 0.05, these two features are also significant. But, because two features have p-values > 0.05 (aka math and science), these two features are not significant, so the model may be improved by removing these two features. There is some mild concern that the residuals are not normally distributed based on a negative skew and a kurtosis less than 3, especially since this P of both Omnibus and JB are less than 0.05, which suggests we can reject the null that they are normally distributed. And with a high Condition number, there is a likelihood that some of these features are correlated with each other. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5 / 9 \n",
    "- Find the model's coefficents using the closed-form solution for linear regression:  <span style=\"color:red\" float:right>[3 point] of 28 pts</span>\n",
    "\n",
    "$${b} = ({X'}{X})^{-1}{X'}{Y}$$ \n",
    "\n",
    "To make it easy, we have created a matrix `M` which is the matrix $X$ with an extra column of 1s for the intercept term. Make sure the results match what's reported in the above model summary. HINT: You can use `np.linalg.inv` to invert a matrix, `np.matmul` to multiply two matrices, and the `np.transpose()` method to take the transpose of a matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1. 57. 52. 41. 47.]\n",
      " [ 1. 68. 59. 53. 63.]\n",
      " [ 1. 44. 33. 54. 58.]\n",
      " [ 1. 63. 44. 47. 53.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 7.2060275 ,  0.38075199,  0.37518056,  0.13222368, -0.02794164])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#concatenate: join a series of arrays along axis = 1\n",
    "    #1st: array filled with ones with a length the same as Y --> reshaped to be (-1):Auto-calculate rows and +1 columns\n",
    "    #2nd: array of values inside X\n",
    "M = np.concatenate([np.ones(len(Y)).reshape(-1, 1), X.values], axis = 1)\n",
    "print(M[:4, :]) #print first 4 rows and all (6)columns\n",
    "#M.shape #200 rows and 6 columns\n",
    "    #I don't think there should be 6 col, should be 5: 4 features + 1 constant\n",
    "\n",
    "#to find the model's coefficients using the formula (vs. the two models)\n",
    "transposed_M = np.transpose(M)\n",
    "#print(transposed_M)\n",
    "multiplied = np.matmul(transposed_M, M)\n",
    "#print(multiplied)\n",
    "parentheses = np.linalg.inv(multiplied)\n",
    "#print(parentheses)\n",
    "beta = np.matmul(np.matmul(parentheses, transposed_M), Y)\n",
    "beta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6 / 9 \n",
    "- The `fit` method used by `sm.ols` has an argument called `normalize`. Use it to train the same model but using the normalized features instead. What changes do you notice in the model summary? <span style=\"color:red\" float:right>[2 point]</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model is at y= read       3.894054\n",
      "write      3.547280\n",
      "math       1.235630\n",
      "science   -0.275955\n",
      "dtype: float64 x_f +  52.405\n",
      "The accuracy is  47.72\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  socst   R-squared:                       0.477\n",
      "Model:                            OLS   Adj. R-squared:                  0.466\n",
      "Method:                 Least Squares   F-statistic:                     44.49\n",
      "Date:                Tue, 18 Mar 2025   Prob (F-statistic):           1.65e-26\n",
      "Time:                        14:41:41   Log-Likelihood:                -693.15\n",
      "No. Observations:                 200   AIC:                             1396.\n",
      "Df Residuals:                     195   BIC:                             1413.\n",
      "Df Model:                           4                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         52.4050      0.555     94.506      0.000      51.311      53.499\n",
      "read           3.8941      0.818      4.759      0.000       2.280       5.508\n",
      "write          3.5473      0.760      4.669      0.000       2.049       5.046\n",
      "math           1.2356      0.831      1.487      0.139      -0.403       2.874\n",
      "science       -0.2760      0.784     -0.352      0.725      -1.822       1.271\n",
      "==============================================================================\n",
      "Omnibus:                        6.177   Durbin-Watson:                   1.932\n",
      "Prob(Omnibus):                  0.046   Jarque-Bera (JB):                6.368\n",
      "Skew:                          -0.428   Prob(JB):                       0.0414\n",
      "Kurtosis:                       2.827   Cond. No.                         2.92\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alissa\\AppData\\Local\\Temp\\ipykernel_7988\\3611962062.py:23: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  print(\"The model is at y=\",results_normalized.params[1:],\"x_f + \", results_normalized.params[0])\n"
     ]
    }
   ],
   "source": [
    "#Apply normalization to data\n",
    "X_copy = X.copy()\n",
    "X_normalized = X.copy()\n",
    "for each in X_copy.columns: \n",
    "    X_normalized[each]= ( X_copy[each] - np.mean(X_copy[each]) )/ np.std(X_copy[each])\n",
    "\n",
    "# Add a constant term to X (required for statsmodels OLS)\n",
    "    #renamed X because it added a constant, which threw off the concatenation below\n",
    "X_OLS_normalized = statsmodels.add_constant(X_normalized)\n",
    "\n",
    "#initialize the model \n",
    "model_statsmodels_normalized = statsmodels.regression.linear_model.OLS(Y,X_OLS_normalized)\n",
    "\n",
    "#fit the data \n",
    "    #input is reading, writing, math, and science scores (X)\n",
    "    #output is scores in social studies (Y)\n",
    "results_normalized = model_statsmodels_normalized.fit()\n",
    "\n",
    "#Predictions are added as a new column\n",
    "hsb2[\"socst_pred_ols\"] = results_normalized.predict(X_OLS_normalized)\n",
    "\n",
    "#Print the linear model\n",
    "print(\"The model is at y=\",results_normalized.params[1:],\"x_f + \", results_normalized.params[0])\n",
    "\n",
    "#Print the score (aka mean accuracy) of the model\n",
    "print(\"The accuracy is \", round(results_normalized.rsquared*100,2))\n",
    "\n",
    "#Print the summary\n",
    "print(results_normalized.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I don't notice too many relatively large differences between the two models of not normalized vs normalized features. They share similar positive and negative qualities. The only relatively big difference is that the condition number has minimized to 3, which suggests features no longer share any correlation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7 / 9 \n",
    "\n",
    "NOTE: We say that ordinary least squares is **invariant to normalization**, while other methods we learn later such as lasso or ridge regression are not.\n",
    "\n",
    "- Train a new model with `sm.ols` but this time only include the reading and writing scores as features. Decide if you should use a model *with or without* interactions. HINT: Change the formula from `Y ~ X_1 + X_2` to `Y ~ X_1 * X_2` and the new model will estimate the main effects $\\beta_\\text{read}$ and $\\beta_\\text{write}$ and their interaction $\\beta_\\text{read:write}$. <span style=\"color:red\" float:right>[2 point]</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  socst   R-squared:                       0.472\n",
      "Model:                            OLS   Adj. R-squared:                  0.464\n",
      "Method:                 Least Squares   F-statistic:                     58.32\n",
      "Date:                Tue, 18 Mar 2025   Prob (F-statistic):           5.45e-27\n",
      "Time:                        14:41:41   Log-Likelihood:                -694.21\n",
      "No. Observations:                 200   AIC:                             1396.\n",
      "Df Residuals:                     196   BIC:                             1410.\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept     15.2578     17.391      0.877      0.381     -19.040      49.555\n",
      "read           0.2853      0.359      0.795      0.428      -0.423       0.993\n",
      "write          0.2866      0.326      0.879      0.381      -0.357       0.930\n",
      "read:write     0.0025      0.006      0.393      0.695      -0.010       0.015\n",
      "==============================================================================\n",
      "Omnibus:                        7.605   Durbin-Watson:                   1.961\n",
      "Prob(Omnibus):                  0.022   Jarque-Bera (JB):                7.767\n",
      "Skew:                          -0.483   Prob(JB):                       0.0206\n",
      "Kurtosis:                       2.988   Cond. No.                     9.27e+04\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 9.27e+04. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "#initialize the model \n",
    "    #Col names: read \twrite \tmath \tscience \tsocst\n",
    "    #input is reading, writing, math, and science scores (X)\n",
    "    #output is scores in social studies (Y)\n",
    "model_formula = sm.ols(formula = 'socst ~ read * write', data=hsb2)\n",
    "\n",
    "#fit the data \n",
    "results_formula = model_formula.fit()\n",
    "\n",
    "#Print the summary\n",
    "print(results_formula.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the p of the read:write interaction is > 0.05, it suggests that we should use a model without this interaction. This and the p has increased for each of the coefficients, which shows including this interaction would not be worthwhile. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8 / 9 \n",
    "\n",
    "- So far we've only had models with numeric features, but it's possible to also include **categorical features**. Add the term `C(prog)` to the formula. This will add the feature `prog` to the model as a categorical feature. This feature states which of 3 after-school program a student participated in. <span style=\"color:red\" float:right>[2 point]</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  socst   R-squared:                       0.495\n",
      "Model:                            OLS   Adj. R-squared:                  0.485\n",
      "Method:                 Least Squares   F-statistic:                     47.78\n",
      "Date:                Tue, 18 Mar 2025   Prob (F-statistic):           5.84e-28\n",
      "Time:                        14:41:41   Log-Likelihood:                -689.69\n",
      "No. Observations:                 200   AIC:                             1389.\n",
      "Df Residuals:                     195   BIC:                             1406.\n",
      "Df Model:                           4                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "================================================================================\n",
      "                   coef    std err          t      P>|t|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------\n",
      "Intercept       13.4029      3.755      3.569      0.000       5.997      20.809\n",
      "C(prog)[T.2]     1.9098      1.431      1.335      0.184      -0.912       4.732\n",
      "C(prog)[T.3]    -2.5976      1.612     -1.612      0.109      -5.776       0.581\n",
      "read             0.3780      0.068      5.528      0.000       0.243       0.513\n",
      "write            0.3583      0.074      4.845      0.000       0.212       0.504\n",
      "==============================================================================\n",
      "Omnibus:                        6.641   Durbin-Watson:                   1.943\n",
      "Prob(Omnibus):                  0.036   Jarque-Bera (JB):                6.837\n",
      "Skew:                          -0.449   Prob(JB):                       0.0328\n",
      "Kurtosis:                       2.881   Cond. No.                         527.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "#initialize the model \n",
    "    #Col names: read \twrite \tmath \tscience \tsocst\n",
    "        #add the categorical feature: prog\n",
    "    #input is reading, writing, math, and science scores (X)\n",
    "    #output is scores in social studies (Y)\n",
    "#model_formula = sm.ols(formula = 'socst ~ read + write + math + science + C(prog)', data=hsb2)\n",
    "model_formula = sm.ols(formula = 'socst ~ read + write + C(prog)', data=hsb2)\n",
    "\n",
    "\n",
    "#fit the data \n",
    "results_formula = model_formula.fit()\n",
    "\n",
    "#Print the summary\n",
    "print(results_formula.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9 / 9 \n",
    "\n",
    "- Report the important results in the model summary. <span style=\"color:red\" float:right>[5 point]</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <b>R-squared</b>: Is 0.495 --> Okay since it's in the middle of [0, 1]\n",
    "- <b>Adj. R-squared</b>: Is 0.485 --> Okay since it's in the middle of [0, 1]\n",
    "- <b>F-statistic</b>: Is 47.78 \n",
    "- <b>Prob (f-statistic)</b>: 5.84e-28 --> Really good (significant) since it's < alpha of 0.05. \n",
    "- <b>Log-Likelihood</b>: -689.69 --> Relatively similar to other models we've run\n",
    "- <b>AIC</b>: 1389 --> Relatively similar to other models we've run\n",
    "- <b>BIC</b>: 1406 --> Relatively similar to other models we've run\n",
    "- <b>Coefficients</b>:\n",
    "    - Intercept: 0.000 --> Really good (significant) since it's < alpha of 0.05\n",
    "    - C: 0.184 and 0.109 --> Not great (not significant) since it's > alpha of 0.05\n",
    "    - Read: 0.000 --> Really good (significant) since it's < alpha of 0.05\n",
    "    - Write: 0.000 --> Really good (significant) since it's < alpha of 0.05\n",
    " \n",
    "- <b>Omnibus</b>: 6.641 --> because this is greater than zero, suggests residuals are not perfectly normally distributed\n",
    "- <b>Prob(Omnibus)</b>: Is 0.036 --> Alright (somewhat significant) since it's < alpha of 0.05, so we can reject the null and say that the data is not normally distributed, but it's close\n",
    "- <b>Skew</b>: -0.449 --> Since it's negative, suggests that residuals are mildly skewed to the left\n",
    "- <b>Kurtosis</b>: 2.881 --> Since it's < 3, suggests that there are tails mildly smaller than a normal distribution\n",
    "- <b>Durbin-Watson</b>: 1.943 --> Since it's <2, suggests that is some mild positive autocorrelation\n",
    "- <b>Jarque-Bera</b>: 6.837 --> because this is greater than zero, suggests residuals are not perfectly normally distributed\n",
    "- <b>Prob(JB)</b>: 0.0328 --> Alright (somewhat significant) since it's < alpha of 0.05, so we can reject the null and say that the data is not normally distributed, but it's close\n",
    "- <b>Cond. No</b>: 527 --> since this is higher than 30, suggests multicollinearity might be a problem (aka some of the features are correlated with each other)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End of assignment"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "235.05px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
